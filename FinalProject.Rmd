#Final Project
#Name: Tony Vo & Santhosh M Reddy
#DSA 5103 Intelligent Data Analytics
#Date: 12/10/2016

```{r}
#libraries
setwd("C:/Users/voton/Documents/R/DSA5103_Final")
library(VIM)  
library(mice)  
library(tidyr)  
library(ggplot2)
library(dplyr)
library(lubridate)
library(wesanderson)
library(caret)
library(randomForest)
library(e1071)
library(VIM)
library(ROCR)
library(pROC)
library(xgboost)
library(MLmetrics)
```

```{r}
#Functions

#Convert the age to num of days
convertToDays = function(n,num,age){
  y = vector(mode = "numeric", length = n)
  for (i in 1:n) {
   y[i] <- ifelse(grepl("year",age[i]),num[i] * 365,
            ifelse(grepl("month", age[i]),num[i] * 30,
            ifelse(grepl("week", age[i]),num[i] * 7,
            ifelse(grepl("day", age[i]),num[i], "" ))))
  }
  return (y)
}

#Convert Time to period of day
convertToPeriod = function(n,t){
  y = vector(mode = "character", length = n)
  for (i in 1:n) {
   y[i] <- ifelse(t[i]>=6 && t[i] < 12,"Morning",
            ifelse(t[i]>=12 && t[i] < 18,"Afternoon",
            ifelse(t[i]>=18 || t[i] < 06,"Night-time", "" )))
  }
  return (y)
}

#Converts animal coat colors to common colors
convertToColor = function(n,t){
  y = vector(mode = "character", length = n)
  for (i in 1:n) {
   y[i] <- ifelse(t[i]=="Lilac"||t[i]=="Lynx"||t[i]=="Silver"||t[i]=="Blue"||t[i]=="Gray","Gray",
            ifelse(t[i]=="Seal"||t[i]=="Black","Black",
            ifelse(t[i]=="Agouti"||t[i]=="Chocolate"||t[i]=="Liver"||t[i]=="Ruddy"||t[i]=="Brown","Brown",
            ifelse(t[i]=="Apricot"||t[i]=="Flame"||t[i]=="Fawn"||t[i]=="Gold"||t[i]=="Tan"||t[i]=="Red"||t[i]=="Yellow"||t[i]=="Orange","Orange",
            ifelse(t[i]=="Cream"||t[i]=="Buff"||t[i]=="Pink"||t[i]=="White","White",
            ifelse(t[i]=="Calico"||t[i]=="Sable"||t[i]=="Tortie"||t[i]=="Torbie"||t[i]=="Tricolor","Multi",NA))))))
  }
  return (y)
}

#Creates dummy variables for colors
createColorVar = function(n,t1,t2,color){
  y = vector(mode = "numeric", length = n)
  for (i in 1:n) {
    y[i] <- ifelse(t1[i]==color || t2[i]==color,1,0)
  }
  return (y)
}
```

```{r}
animalRaw <- read.csv("animalTrain.csv", stringsAsFactors = F)
test <- read.csv("animalTest.csv",stringsAsFactors = F)
train <- animalRaw
head(train)
dim(train)
str(train)
```

```{r}
#Data Preparation & Feature Construction

#Cleaning 'Name'
train$Name <- ifelse(nchar(train$Name) == 0, "Unknown", train$Name) #Change blank names to 'noname'
train$NameStatus <- if_else(train$Name == 'Unknown', 0, 1) #Add new variable indicating if name known or not

#Cleaning 'SexuponOutcome'
#In 'SexuponOutcome' there is only one missing value, so imputed with mode
table(train$SexuponOutcome)  #'Neutered Male' most common
train$SexuponOutcome[train$SexuponOutcome == ""] = "Neutered Male"
train = separate(train, SexuponOutcome, c("IntactStatus", "Sex"), sep = " ") #Separate 'SexuponOutcome' and add 'IntactStatus'
train$Sex[train$IntactStatus=="Unknown"] = "Unknown"

#Cleaning 'DateTime
train$Year <- year(train$DateTime) #Add 'Year' predictor
train = train %>% mutate(Month = month.abb[month(train$Date)])
train$Weekday <- wday(train$DateTime, label=TRUE) #Add 'wday' predictor
train = separate(train, DateTime , c("Date", "Time"), sep = " ", extra = "merge" ) #Separate 'DateTime' 
train$Date = as.Date(train$Date)
train = separate(train, Time, c("timeHr", "timeMin"), sep = ":", remove = FALSE, extra = "merge") #Separate 'Time'
train$timeHr = as.numeric(train$timeHr)
train$timePeriod = convertToPeriod(nrow(train), train$timeHr) #Add 'timePeriod' based on Time
train = subset(train, select = -c(timeHr,timeMin))

#Cleaning 'Breed'
train = separate(train, Breed, c("Breed", "isMix"), sep = " Mix") #Separate Breed, adding new predictor 'isMix'
train$isMix <- if_else(train$isMix == "", 1, 0, missing = 0) #1 if mixed breed, 0 else

#Cleaning 'AgeuponOutcome'
#Standardize 'AgeuponOutcome' to Days
train <- separate(train, AgeuponOutcome, c("num", "AgeInDays"), sep = " ")
train$num <- as.numeric(train$num)
train$AgeInDays <- convertToDays(nrow(train),train$num,train$AgeInDays)
train$num <- NULL

#Change blanks and '0 Days' to NA for ages
train$AgeInDays[train$AgeInDays == ""] = NA
train$AgeInDays[train$AgeInDays==0] = NA  #22 records with '0 years' changed to NA

#Impute NA values in 'AgeInDays' using pmm
set.seed(42)
x1 = c("OutcomeType","NameStatus","AnimalType","IntactStatus","Sex","isMix","AgeInDays","Year","Month","Weekday","timePeriod")
miceDF = train[,x1]
miceDF[,x1] = lapply(miceDF[,x1],as.factor) #Change to correct class
miceDF$AgeInDays = as.numeric(as.character(miceDF$AgeInDays)) #Change Age to numeric
train$AgeInDays = mice::complete(mice(miceDF))$AgeInDays  #Perform mice 

#Categorize 'Color' predictor based on common dog/cat colors
#Create 6 binary color predictors for colors:black,gray,brown,orange,white,multi
temp = separate(train, Color, c("color1", "color2"), sep = "/", remove = FALSE) 
temp = separate(temp, color1, c("color1.1", "color1.2"), sep = " ", remove = FALSE, extra = "merge")
temp = separate(temp, color2, c("color2.1", "color2.2"), sep = " ", remove = FALSE, extra = "merge")
temp$RColor1 = convertToColor(nrow(temp),temp$color1.1)
temp$RColor2 = convertToColor(nrow(temp),temp$color2.1)
temp$RColor2[is.na(temp$RColor2)] = " "
train$isBlack = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"Black") #Black,Seal
train$isGray = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"Gray") #Gray,Blue,Lilac,Lynx,Silver
train$isBrown = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"Brown") #Brown,Agouti,Chocolate,Liver,Ruddy
train$isOrange = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"Orange") #Orange,Apricot,Flame,Fawn,Gold,Tan,Red,Yellow
train$isWhite = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"White") #White,Cream,Buff,Pink
train$isMulti = createColorVar(nrow(temp),temp$RColor1,temp$RColor2,"Multi") #Calico,Sable,Tortie,Torbie,Tricolor

#Remove 'OutcomeSubType' predictor & 'AnimalID'
#This predicted was highly correlated with the 'OutcomeType' since it could only be identified at the time of the outcome
#Also over half of the data in this column was missing
train = subset(train,select = -c(OutcomeSubtype,AnimalID,Name,Date,Time,Breed,Color))

#Change predictors to correct classes
str(train)
x2 = c("OutcomeType","AnimalType","IntactStatus","Sex","isMix","NameStatus","Year","Month","timePeriod","isBlack","isGray","isBrown","isOrange","isWhite","isMulti")
train[,x2] = lapply(train[,x2],as.factor)
str(train)

#Holdout validation, 80% training & 20% test
inTr = createDataPartition(train$OutcomeType, p=.8, list = FALSE)
tr = train[inTr,]
te = train[-inTr,]
```

```{r}
#Data Visualization

#Missingness visualization
miss = animalRaw
miss[miss==""] = NA
miss$OutcomeSubtype = NULL
miss$Name[is.na(miss$Name)] = "Unknown"
aggr(miss, cex.lab = 1.5, cex.axis = .59)

#Outcome type distribution
ggplot(train, aes(x = factor(train$OutcomeType, levels=names(sort(table(train$OutcomeType),decreasing = TRUE))))) +
  geom_bar(stat="count") + labs(x='Outcome Type', title='Outcome Type Distribution')

#Animal Type based on Name Status
k1 = data.frame(table(train$AnimalType,train$NameStatus))
ggplot(k1, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys",labels=c('No Name','Named')) +
  labs(y='Proportion of Animals',x='Animal Type',title='Name vs No Name by Animal Type',fill='factors')

#Animal Type vs Outcome Type
k2 = data.frame(table(train$AnimalType,train$OutcomeType))
ggplot(k2, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') + coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Animal Type',title='Outcomes by Animal Type',fill='Outcomes')

#Name Status vs Outcome Type
k3 = data.frame(table(train$NameStatus,train$OutcomeType))
ggplot(k3, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Animal Type',title='Outcomes by Animal Type',fill='Outcomes') +
  scale_x_discrete(labels=c('1' = 'Named', '0' = 'Nameless'))

#Mixed Breed Status vs Outcome Type
k4 = data.frame(table(train$isMix,train$OutcomeType))
ggplot(k4, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Mixed Breed Status',title='Outcomes by Mixed Breed Status',fill='Outcomes') +
  scale_x_discrete(labels=c('1' = 'Mixed ', '0' = 'Not Mixed'))
  
#Intact Status vs Outcome Type
k5 = data.frame(table(train$IntactStatus,train$OutcomeType))
ggplot(k5, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Intact Status',title='Outcomes by Intact Status Status',fill='Outcomes')

# week days vs outcome type
k6 = data.frame(table(train$Weekday,train$OutcomeType))
ggplot(k6, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Intact Status',title='Outcomes by Weekdays',fill='Outcomes')

# month vs outcometype
k7 = data.frame(table(train$Month,train$OutcomeType))
ggplot(k7, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Intact Status',title='Outcomes by Month',fill='Outcomes')

#Outcome types by year
k8 = data.frame(table(train$Year,train$OutcomeType))
ggplot(k8, aes(x = Var1, y = Freq, fill = as.factor(Var2)))+geom_bar(stat = 'identity', position = 'fill',color='black') +  coord_flip() + scale_fill_brewer(palette = "Greys") +
  labs(y='Proportion by Outcome',x='Intact Status',title='Outcomes by Year',fill='Outcomes')

#Age in days density distribution
plot(density(table(train$AgeInDays)), main="Animal Age in Days",cex.axis = 1.5, cex.lab=1.6,cex.main=2)
```

```{r}
#Modeling
#Methods used: Logistic regression, Random Forest, SVM, Neural Networks, and XGBoosted

#caret used to tune Random Forest, Neural Networks, and XGBoosted
#Sets up 5-fold cross validation for train function of caret
set.seed(123)
cv.5.folds = createMultiFolds(tr$OutcomeType, k = 5, times = 5)
ctrl = trainControl(method="cv", number = 5, index = cv.5.folds, 
                    classProbs = TRUE, summaryFunction = multiClassSummary)
```

```{r}
#Logistic Regression

#Data preparation for glmnet
x <- model.matrix(OutcomeType~.,data = tr)
y <- tr$OutcomeType
train_rows <- sample(1:dim(x)[[1]], .70*dim(x)[[1]])
training.x <- x[train_rows,]
testing.x <- x[-train_rows,]
 
#glmnet with 5-fold cross validation
set.seed(567)
 cvfit <- cv.glmnet(x, y, family="multinomial", type.multinomial = "grouped", parallel = TRUE, nfolds = 5)
 
plot(cvfit)  #cross validation curve
predGLM <- predict(cvfit, newx = testing.x, s = "lambda.min", type = "class")
confusionMatrix(predGLM[,1], y[-train_rows]) #confusion matrix

# plot roc and auc value
roc.cv <- multiclass.roc(as.numeric(as.factor(predGLM)), as.numeric(y[-train_rows]))
rocb <- roc(as.numeric(as.factor(predGLM)), as.numeric(y[-train_rows]))
plot(rocb, print.auc=T, auc.polygon=T, max.auc.polygon=T,
     auc.polygon.col="yellow", print.thres=T, col = "green")
```

```{r}
#Random Forest

set.seed(321)
rf.model = train(OutcomeType ~ ., data = tr, method = "rf",
                 tuneLength = 3, ntree = 500, trControl = ctrl,metric = "logLoss")

#The final value used for the model was mtry = 19. 

predRF = predict(rf.model, te, probability = TRUE)
confusionMatrix(predRF, te$OutcomeType) #confusion matrix

#Outcome type error rates & OOB plot
plot(rf.model$finalModel, main = "RF Outcome Type Error Rates",
     cex.axis = 1.5, cex.lab = 1.5, cex.main = 2)
legend("topright",c("OOB","Adopt","Death","Euthanasia","Returned", "Transfer"),lty=1:6,fill = 1:6)

```

```{r}
#Support Vector Machine

#Set up 5-fold cross validation for SVM
tc = tune.control(cross = 5)

#Perform first tune with cost from 0 to 10, gamma from 0 to 0.1
svm.tune.1 = tune.svm(OutcomeType ~ ., data = tr, cost = 10^(-3:1), gamma = 10^(-5:-1),
tunecontrol = tc)

plot(svm.tune.1)  #Performance plot

optGamma = svm.tune.1$best.parameters[,1] #Get optimal gamma
optCost = svm.tune.1$best.parameters[,2] #Get optimal cost

#Perform SVM with optimal parameters
set.seed(789)
svm.model = svm(OutcomeType ~ ., data = tr, method = "C-classification", kernel = "radial" ,
                cost = optCost, gamma = optGamma, probability = TRUE)
      
predSVM <- predict(svm.model, te, probability = TRUE)
confusionMatrix(predSVM, te$OutcomeType) #confusion matrix

#Get log loss and AUC of model
MLmetrics::MultiLogLoss(y_true = te$OutcomeType, y_pred = attr(predSVM, "probabilities"))
multiclass.roc(as.numeric(as.factor(predSVM)), as.numeric(te$OutcomeType))
```

```{r}
#Neural Network

#nnet 5-fold cross validation
set.seed(345)
nn.model = train(OutcomeType ~ ., data = tr, method = "nnet", 
                 tuneLength = 5, trControl = ctrl, metric = "logLoss")

#The final values used for the model were size = 9 and decay = 0.1.

predNN = predict(nn.model, newdata = te, type = "raw")
confusionMatrix(predNN, te$OutcomeType) #confusion matrix

#Size & decay tuning plot
plot(nn.model, main = "NN Size & Decay Tuning",
     cex.axis = 1.5, cex.lab = 1.5)
```

```{r}
#xgb

#Creates grid which parameters will be tuned for
#tuning for depth, gamma, colsample_bytree, and min_child_weight
xgb_grid = expand.grid(nrounds = 30, max_depth = c(3, 6, 10 ), eta = 0.2, gamma = c(0.1,.5,1), 
                         colsample_bytree = c(0.4, 0.7, 1.0), min_child_weight = c(0.5, 1, 1.5))

set.seed(234)
xgb.model = train(OutcomeType ~ ., data = tr, method = "xgbTree",
                 tuneGrid = xgb_grid, trControl = ctrl, metric = "logLoss")

#optimal parameters
#nrounds max_depth eta gamma colsample_bytree min_child_weight
#     30         6 0.2   0.1                1            1

predXGB = predict(xgb.model, newdata=te, type = "raw")
confusionMatrix(predXGB, te$OutcomeType) #confusion matrix

#Get importance from optimal XGBoost model
Impor = varImp(xgb.model)$importance

#Plots Top 10 Important predictors
barplot(Impor[1:10,], names.arg = rownames(Impor)[1:10], las = 2,
        ylab = "Importance", main = "Predictor Importance")
```

```{r}
#Model heatmaps for algorithm confusion matrices
#source code: http://sebastianraschka.com/Articles/heatmaps_in_r.html

# creates a color palette from red to green
my_palette <- colorRampPalette(c("red", "yellow", "green"))(n = 299)

#Store confusion matrices for each algorithm
glm.ConfMat = as.matrix.data.frame(confusionMatrix(predGLM[,1], y[-train_rows])$table)
rf.ConfMat = as.matrix.data.frame(confusionMatrix(predRF, te$OutcomeType)$table)
svm.ConfMat = as.matrix.data.frame(confusionMatrix(predSVM, te$OutcomeType)$table)
nn.ConfMat = as.matrix.data.frame(confusionMatrix(predNN, te$OutcomeType)$table)
xgb.ConfMat = as.matrix.data.frame(confusionMatrix(predXGB, te$OutcomeType)$table)

#GLM heat map
heatmap.2(glm.ConfMat, cellnote = glm.ConfMat, notecex = 2 ,  main = "Logistic Regression Confusion Matrix Heatmap",
          notecol="black", density.info="none", trace="none", margins =c(12,9), col=my_palette,revC = TRUE,  
          dendrogram="row", Colv="NA",Rowv = NULL, labRow = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"),
          labCol = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"), cexRow = 1.5, cexCol = 1.5, key = FALSE)
#RF heat map
heatmap.2(rf.ConfMat, cellnote = rf.ConfMat, notecex = 2 ,  main = "Random Forest Confusion Matrix Heatmap",
          notecol="black", density.info="none", trace="none", margins =c(12,9), col=my_palette,  
          dendrogram="row", Colv="NA", labRow = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"),
          labCol = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"), cexRow = 1.5, cexCol = 1.5, key = FALSE)
#SVM heat map
heatmap.2(svm.ConfMat, cellnote = svm.ConfMat, notecex = 2 ,  main = "SVM Confusion Matrix Heatmap",
          notecol="black", density.info="none", trace="none", margins =c(12,9), col=my_palette,  
          dendrogram="row", Colv="NA", labRow = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"),
          labCol = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"), cexRow = 1.5, cexCol = 1.5, key = FALSE)
#NN heat map
heatmap.2(nn.ConfMat, cellnote = nn.ConfMat, notecex = 2 ,  main = "Neural Network Confusion Matrix Heatmap",
          notecol="black", density.info="none", trace="none", margins =c(12,9), col=my_palette,  
          dendrogram="row", Colv="NA", labRow = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"),
          labCol = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"), cexRow = 1.5, cexCol = 1.5, key = FALSE)
#XGB heat map
heatmap.2(xgb.ConfMat, cellnote = xgb.ConfMat, notecex = 2 ,  main = "XGBoost Confusion Matrix Heatmap",
          notecol="black", density.info="none", trace="none", margins =c(12,9), col=my_palette,  
          dendrogram="row", Colv="NA", labRow = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"),
          labCol = c("Adoption", "Died", "Euthanasia", "Returned", "Transfer"), cexRow = 1.5, cexCol = 1.5)
```

